{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdad8ab-ce08-42e7-a113-92da68474cf1",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "1. Clone the repository\n",
    "2. run fetch_SanchezSaez2020\n",
    "3. run create_datasets\n",
    "4. Cringe: I can't use seed in ppca bc my pull request hasn't been accepted. Should I just copy the code?\n",
    "5. Every section has its notebook, each notebook many tests\n",
    "6. Each test has a section that builds the data/ part, mainly data preprocessing, big so I cannot put it on github\n",
    "7. Then once the data is created it's analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43da4b-8984-4e2f-9547-013622089cd0",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7f6c85-3201-4ffb-b221-55e47761544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import importlib\n",
    "from ppca import PPCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from utils.testers import ss, assess\n",
    "from utils.reporters import basic_scores, bs_rankings, bs_curves\n",
    "from utils.helpers import mask50\n",
    "importlib.reload(utils.reporters)\n",
    "importlib.reload(utils.testers)\n",
    "importlib.reload(utils.helpers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcae47-dc14-4ba2-b026-cab73a63fbad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Data\n",
    "The training data were lightcurves from ZTF alerts, labeled according to different catalogs as described in the articles.\n",
    "\n",
    "The publicly available data related to the LC classifier is composed of three .csv files: \n",
    "- `labeled_set_lc_classifier_SanchezSaez_2020.csv` (~10MB) aka `labels_file`: the training set with columns ZTF id, label, celestial coordinates, catalog (e.g. MILLIQUAS) and catalog id.\n",
    "- `features_for_lc_classifier_20200609.csv` (~2.2GB) aka `features_file`: the complete dataset containing the labeled events as well as unlabeled events for testing, with columns ZTF id and the 183 features.\n",
    "- `ALeRCE_lc_classifier_outputs_ZTF_unlabeled_set_20200609.csv` (~300MB) aka `test_file`: the test set with columns ZTF id, celestial coordinates, probabilities of belonging to each class, predicted class and predicted class probability.\n",
    "\n",
    "ZTF id is called OID in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c6e39-3c3b-4960-82f5-7295971a2173",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert .csv to .pkl for faster pandas reading, just one time\n",
    "\n",
    "raw_data_path = \"data/raw/\"\n",
    "features_filename = \"features_for_lc_classifier_20200609.csv\"\n",
    "labels_filename = \"labeled_set_lc_classifier_SanchezSaez_2020.csv\"\n",
    "test_filename = \"ALeRCE_lc_classifier_outputs_ZTF_unlabeled_set_20200609.csv\"\n",
    "\n",
    "features_file = pd.read_csv(raw_data_path + features_filename,index_col=\"oid\")\n",
    "labels_file = pd.read_csv(raw_data_path + labels_filename,index_col=\"oid\")\n",
    "test_file = pd.read_csv(raw_data_path + test_filename,index_col=\"oid\")\n",
    "\n",
    "features_file.to_pickle(raw_data_path + \"features_file.pkl\")\n",
    "labels_file.to_pickle(raw_data_path + \"labels_file.pkl\")\n",
    "test_file.to_pickle(raw_data_path + \"test_file.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322e52c7-d92d-4b45-bca3-94b388b8fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast data import\n",
    "\n",
    "features_file = pd.read_pickle(raw_data_path + \"features_file.pkl\")\n",
    "labels_file = pd.read_pickle(raw_data_path + \"labels_file.pkl\")\n",
    "test_file = pd.read_pickle(raw_data_path + \"test_file.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0adb3a7-6858-4b15-a51e-73380ee676a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select \"transient\" (supernovae) samples and save them as .pkl\n",
    "\n",
    "transient_classes = [\"SNIa\", \"SNIbc\", \"SNII\", \"SLSN\"]\n",
    "transient_labeled = labels_file[labels_file[\"classALeRCE\"].isin(transient_classes)]\n",
    "transient_features = features_file.loc[transient_labeled.index]\n",
    "transient_labeled.to_pickle(\"data/transient_labeled.pkl\")\n",
    "transient_features.to_pickle(\"data/transient_features.pkl\")\n",
    "\n",
    "# select \"stochastic\" (supernovae) samples and save them as .pkl\n",
    "\n",
    "stochastic_classes = [\"QSO\", \"AGN\", \"Blazar\", \"YSO\", \"CV/Nova\"]\n",
    "stochastic_labeled = labels_file[labels_file[\"classALeRCE\"].isin(stochastic_classes)]\n",
    "stochastic_features = features_file.loc[stochastic_labeled.index]\n",
    "stochastic_labeled.to_pickle(\"data/stochastic_labeled.pkl\")\n",
    "stochastic_features.to_pickle(\"data/stochastic_features.pkl\")\n",
    "\n",
    "# select \"periodic\" (variable stars) samples and save them as .pkl\n",
    "\n",
    "periodic_classes = [\"LPV\",\"E\",\"DSCT\",\"RRL\",\"CEP\",\"Periodic-Other\"]\n",
    "periodic_labeled = labels_file[labels_file[\"classALeRCE\"].isin(periodic_classes)]\n",
    "periodic_features = features_file.loc[periodic_labeled.index]\n",
    "periodic_labeled.to_pickle(\"data/periodic_labeled.pkl\")\n",
    "periodic_features.to_pickle(\"data/periodic_features.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
